{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xi14g3ezBcpK"
      },
      "outputs": [],
      "source": [
        "# install dependencies\n",
        "%pip install jedi>=0.16\n",
        "%pip install -Uq llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import api key secret from Colab\n",
        "from google.colab import userdata\n",
        "\n",
        "# verify that key can be loaded\n",
        "print(userdata.get('OPENAI_API_KEY')[-4:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU_yE9XuCX2Q",
        "outputId": "12ca660f-676e-4bb3-a00e-eef9439c75e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMUA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure we are inside of /content/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRitXiFMFf-f",
        "outputId": "d298b2d8-8cf8-4dab-84c7-77736117fbfe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=0.16'   \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing llamaindex libraries for RAG agent setupimport os\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# set the OpenAI API key as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# set openai language and embedding models\n",
        "llm_model = OpenAI(model=\"gpt-5-nano-2025-08-07\", temperature=0.1)\n",
        "embedding_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "\n",
        "# check that models were set correctly\n",
        "print(f\"GPT model: {llm_model.model}\")\n",
        "print(f\"embedding model: {embedding_model.model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L65JP5noDZcd",
        "outputId": "0f791129-bf3a-430e-e21f-de887d20a2d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT model: gpt-5-nano-2025-08-07\n",
            "embedding model: text-embedding-3-small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "\n",
        "# create vector store index from documents\n",
        "index = VectorStoreIndex.from_documents(documents, llm_model=llm_model, embed_model=embedding_model)\n",
        "\n",
        "# create query engine that can answer questions about indexed documents\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"When did she become a superstar?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiXy_409asMM",
        "outputId": "da71555b-34b1-426e-efd2-c5189fe1b5ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She became a superstar after executing one of the most successful comebacks in history with her sixth studio album, \"reputation.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "we can persist the indexed data into disk\n",
        "so that we won't have to re-index it later\n",
        "'''\n",
        "\n",
        "import os.path\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "# check if storage already exists\n",
        "PERSIST_DIR = \"./storage\"\n",
        "\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "# Either way we can now query the index\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"When did she become a superstar?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li_SZl1FGGT-",
        "outputId": "3e412ad6-fe23-432c-8bb3-ab50fd666db0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
            "She became a superstar after executing one of the most successful comebacks in history with her sixth studio album, \"reputation.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup llamacloud api key for parsing\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqMwQiIwNg2O",
        "outputId": "b309ff75-7178-414c-ad60-40c90b3333bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "bwmlzjdxNyAj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "# parse document and return plain text version\n",
        "documents = LlamaParse(result_type=\"text\").load_data(\"data/taylor_swift_biography.html\")\n",
        "\n",
        "# create new index from parsed documents\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "# same as before\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"why is she so stuck up on her exes?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HivvrhzNS8L",
        "outputId": "6a914057-63ae-4aab-b996-db3941155d28"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 5536cb7a-787b-478c-9b1e-377c0d4c39f5\n",
            "She often draws inspiration from her personal experiences, including past relationships, to create music that resonates with her audience.\n"
          ]
        }
      ]
    }
  ]
}